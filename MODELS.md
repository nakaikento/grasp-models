# MODELS.md - Grasp ASR/翻訳モデル調査

最終更新: 2026-02-10

## ASRモデル比較

### 評価データ
#### 日本語
- **ソース**: TED Talk 日本語 (高橋晋平「しりとり発想法」)
- **長さ**: 約5.5分 (331秒)
- **参照**: 日本語手動字幕 (1,986文字)

#### 韓国語
- **ソース**: セバシ講演 (인순이)
- **長さ**: 約18分 (1103秒)
- **参照**: YouTube自動字幕 (4,393文字) ※相対比較用

### 結果

| モデル | サイズ | 処理時間 | CER | 評価 |
|--------|--------|----------|-----|------|
| sherpa-onnx Korean (int8) | ~70MB | 高速 | 62.3% | ❌ 実用困難 |
| Whisper base (Korean) | 139MB | ~55s (CPU) | 17.6% | 🟡 良好 |
| **Whisper base-q8 (Korean)** | **78MB** | ~59s (CPU) | **19.5%** | ✅ 推奨 |
| sherpa-onnx ReazonSpeech (FP32) | ~200MB | 高速 | 53.6% | ❌ 実用困難 |
| Whisper tiny | 73MB | ~15s (CPU) | 36.0% | ❌ 要改善 |
| Whisper base | 139MB | ~20s (CPU) | 20.8% | 🟠 許容範囲 |
| Whisper small | 462MB | ~52s (CPU) | 17.8% | 🟡 良好 |

### Whisper.cpp 量子化モデル（推奨）

| モデル | サイズ | 処理時間 | CER | vs非量子化 |
|--------|--------|----------|-----|------------|
| **base-q8** | **78MB** | 19s | **21.9%** | +1.1pt ✅ |
| base-q5 | 57MB | 22s | 23.3% | +2.5pt |
| **small-q8** | **253MB** | 71s | **19.9%** | +2.1pt ✅ |
| small-q5 | 182MB | 74s | 20.2% | +2.4pt |

#### 重要な発見
- **Q8量子化は精度劣化ほぼなし**（1-2ポイント）
- **同サイズでCER 54%→22%** に改善可能（sherpa-onnx比）
- whisper.cpp/pywhispercpp でモバイル実装可能

### CER (Character Error Rate) 目安
- < 10%: 優秀（ほぼ完璧）
- < 20%: 良好
- < 30%: 許容範囲
- > 30%: 要改善

### 所見

#### sherpa-onnx系 (Zipformer Transducer)
- **利点**: 軽量、高速、ストリーミング対応
- **欠点**: CER 50-60%台で精度が低い
- **備考**: リアルタイム処理向けだが、現状の精度では翻訳品質に影響大

#### Whisper系
- **利点**: 高精度（CER 17-21%）
- **欠点**: モデルサイズ大、処理時間長い
- **備考**: 
  - baseでも「こんにちは」→「この日は」等の誤認識あり
  - smallで改善されるが、モバイルリアルタイムには重い

### 誤認識例

**Whisper base:**
- 「こんにちは」→「この日は」
- 「アイデアを」→「間を」
- 「こう言われました」→「こういうわれました」

**Whisper small:**
- 上記の誤りが修正された

---

## 翻訳モデル比較

### 評価データ
- **ソース**: OpenSubtitles KO→JA (1,000サンプル)
- **指標**: chrF++ (主), BLEU (参考)

### 結果

| モデル | chrF++ | BLEU | 速度 | 備考 |
|--------|--------|------|------|------|
| M2M100-418M | 14.9 | 6.6 | 遅い | 品質不足 |
| **Qwen2.5-7B** | **49.3** | 26.8 | 37行/s (RTX4090) | 採用 |

### 所見
- Qwen2.5-7Bが圧倒的に高品質（chrF++ 49 vs 15）
- 現在1.19M行の教師データ生成中（RunPod）

---

## 現行モデル構成 (grasp-ko-ja)

### 日本語ASR
- **モデル**: sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01
- **量子化**: int8
- **CER**: 約54% (要改善)

### 韓国語ASR
- **モデル**: sherpa-onnx-streaming-zipformer-korean-2024-06-16
- **量子化**: int8
- **CER**: 約62% (要改善)

### 翻訳 (JA→KO, KO→JA)
- **モデル**: MarianMT (量子化ONNX)
- **品質**: 要評価

---

## 改善案

### 短期（推奨アクション）
1. **Whisper base-q8 への移行検討** ← 最優先
   - 同サイズ（78MB vs 73MB）でCER 22% vs 54%
   - whisper.cpp / pywhispercpp で実装可能
2. **韓国語ASRも Whisper base-q8 推奨**
   - 現行sherpa-onnx Korean: CER 62%
   - Whisper base: CER 17.6% ← **検証済み（セバシ講演18分）**
   - 日本語と同様の大幅改善を確認

### 中期
1. whisper.cpp Android統合（NDK経由）
2. 教師データでMarianMTファインチューニング
3. Whisper small-q8 (253MB) でさらなる精度向上

### 長期
1. 独自ASRモデルのトレーニング（ドメイン特化）
2. End-to-End Speech Translation

---

## 量子化について

### 形式説明
- **Q8_0**: 8bit量子化 - 精度劣化最小（1-2%）、サイズ約55%
- **Q5_1**: 5bit量子化 - 精度劣化小（2-3%）、サイズ約40%
- **Q4_0**: 4bit量子化 - 精度劣化あり、サイズ約35%

### 推奨
日本語ASRには **Q8_0（int8相当）** を推奨。精度と速度のバランスが最適。
