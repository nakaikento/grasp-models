# MODELS.md - Grasp ASR/翻訳モデル調査

最終更新: 2026-02-11

## ASRモデル比較

### 評価データ
#### 日本語
- **ソース**: TED Talk 日本語 (高橋晋平「しりとり発想法」)
- **長さ**: 約5.5分 (331秒)
- **参照**: 日本語手動字幕 (1,986文字)

#### 韓国語
- **ソース**: セバシ講演 (인순이)
- **長さ**: 約18分 (1103秒)
- **参照**: YouTube自動字幕 (4,393文字) ※相対比較用

### 結果

| モデル | サイズ | 処理時間 | CER | 評価 |
|--------|--------|----------|-----|------|
| sherpa-onnx Korean (int8) | ~70MB | 高速 | 62.3% | ❌ 実用困難 |
| Whisper base (Korean) | 139MB | ~55s (CPU) | 17.6% | 🟡 良好 |
| **Whisper base-q8 (Korean)** | **78MB** | ~59s (CPU) | **19.5%** | ✅ 推奨 |
| sherpa-onnx ReazonSpeech (FP32) | ~200MB | 高速 | 53.6% | ❌ 実用困難 |
| Whisper tiny | 73MB | ~15s (CPU) | 36.0% | ❌ 要改善 |
| Whisper base | 139MB | ~20s (CPU) | 20.8% | 🟠 許容範囲 |
| Whisper small | 462MB | ~52s (CPU) | 17.8% | 🟡 良好 |

### Whisper.cpp 量子化モデル（推奨）

| モデル | サイズ | 処理時間 | CER | vs非量子化 |
|--------|--------|----------|-----|------------|
| **base-q8** | **78MB** | 19s | **21.9%** | +1.1pt ✅ |
| base-q5 | 57MB | 22s | 23.3% | +2.5pt |
| **small-q8** | **253MB** | 71s | **19.9%** | +2.1pt ✅ |
| small-q5 | 182MB | 74s | 20.2% | +2.4pt |

#### 重要な発見
- **Q8量子化は精度劣化ほぼなし**（1-2ポイント）
- **同サイズでCER 54%→22%** に改善可能（sherpa-onnx比）
- whisper.cpp/pywhispercpp でモバイル実装可能

### CER (Character Error Rate) 目安
- < 10%: 優秀（ほぼ完璧）
- < 20%: 良好
- < 30%: 許容範囲
- > 30%: 要改善

### 所見

#### sherpa-onnx系 (Zipformer Transducer)
- **利点**: 軽量、高速、ストリーミング対応
- **欠点**: CER 50-60%台で精度が低い
- **備考**: リアルタイム処理向けだが、現状の精度では翻訳品質に影響大

#### Whisper系
- **利点**: 高精度（CER 17-21%）
- **欠点**: モデルサイズ大、処理時間長い
- **備考**: 
  - baseでも「こんにちは」→「この日は」等の誤認識あり
  - smallで改善されるが、モバイルリアルタイムには重い

### 誤認識例

**Whisper base:**
- 「こんにちは」→「この日は」
- 「アイデアを」→「間を」
- 「こう言われました」→「こういうわれました」

**Whisper small:**
- 上記の誤りが修正された

---

## 翻訳モデル比較

### 評価データ

#### 旧評価（OpenSubtitles）
- **ソース**: OpenSubtitles KO→JA (1,000サンプル)
- **品質**: ファンサブベース（参考値）

#### 新評価（AI Hub） ← 推奨
- **ソース**: AI Hub Ko-Ja Translation（人手翻訳）
- **フィルタ**: aihub-71263（放送コンテンツ）+ aihub-546（日常口語）
- **サンプル数**: 1,000〜10,000
- **品質**: 高品質リファレンス

### 結果

| モデル | chrF++ | BLEU | データ | 備考 |
|--------|--------|------|--------|------|
| **Ko-Ja蒸留 (ONNX int8)** | **7.20** | 8.03 | AI Hub | ❌ 壊滅的 |
| **M2M100-418M** | **22.54** | **33.63** | **AI Hub** | 🟠 要改善 |
| **Qwen2.5-7B-Instruct** | **30.01** | **41.23** | **AI Hub** | 🟠 目標未達 |
| Qwen2.5-7B (教師) | 49.3 | 26.8 | OpenSubs | (旧評価) |
| M2M100-418M | 14.9 | 6.6 | OpenSubs | (旧評価) |

### 2026-02-11 AI Hub評価: Qwen2.5-7B-Instruct

#### 設定
- **モデル**: Qwen2.5-7B-Instruct (HuggingFace, bfloat16)
- **データ**: AI Hub 1,000サンプル（放送+日常口語）
- **プロンプト**: "あなたは韓国語から日本語への翻訳者です。翻訳のみを出力してください。"
- **デコード**: Greedy (do_sample=False)

#### 結果
```
chrF++:  30.01  (目標: > 50) ❌ 未達
BLEU:    41.23  (目標: > 30) ✅ 達成
```

#### 翻訳サンプル
```
KO: 저의 어머니께서 전화하고 계신다.
REF: うちの母が電話している。
HYP: 私の母が電話しています。        ✅ 正確

KO: 최대 30만원 차이가 납니다.
REF: 最大30万ウォンの差が出ます。
HYP: 最大30万円の差があります。      🟠 通貨変換ミス

KO: 할머니께서도 하늘나라에서 기뻐해 주셨으면 좋겠는데요.
REF: お祖母さんも天国で喜んでくださると良いのですが。
HYP: 祖母も天の国で喜んでいただけると良いなと思います。  ✅ 意味正確
```

#### 診断
- **OpenSubsとAI Hubで大きな差**: chrF++ 49 vs 30 (≈19pt低下)
- **中国語混入問題**: 一部の翻訳に中国語が混入
- **通貨変換**: 원→円の誤変換
- **ドメイン差**: 映画字幕 vs 放送/日常口語で性能差

#### 考察
- AI Hubは高品質リファレンスだが、モデルがOpenSubtitles（映画字幕）ドメインに特化
- 放送/日常口語ドメインへの適応が必要
- プロンプトエンジニアリングで改善の余地あり

### 2026-02-11 評価: Ko-Ja蒸留モデル

#### 設定
- **モデル**: MarianMT (ONNX int8量子化)
- **データ**: AI Hub 1,000サンプル（放送+日常口語）
- **デコード**: Greedy (KVキャッシュ使用)

#### 結果
```
chrF++:  7.20  (目標: > 50)
BLEU:    8.03  (目標: > 30)
```

#### 翻訳サンプル（問題例）
```
KO: 최대 30만원 차이가 납니다.
REF: 最大30万ウォンの差が出ます。
HYP: 平均30万人の 確率は          ❌ 完全に誤訳

KO: 안녕하세요
HYP: 韓国語: 日本語:               ❌ 意味不明
```

#### 診断
- 蒸留プロセスに問題あり
- 教師モデル（Qwen2.5-7B, chrF++ 49）から大幅劣化
- ONNX量子化だけでなく、safetensors版も同様の問題

### 所見
- Qwen2.5-7Bが圧倒的に高品質（chrF++ 49 vs 7）
- **蒸留モデルは使用不可** → 教師モデル直接使用 or 再学習が必要
- 1.19M行の教師データは生成済み（RunPod）

---

## 現行モデル構成 (grasp-ko-ja)

### 日本語ASR
- **モデル**: sherpa-onnx-zipformer-ja-reazonspeech-2024-08-01
- **量子化**: int8
- **CER**: 約54% (要改善)

### 韓国語ASR
- **モデル**: sherpa-onnx-streaming-zipformer-korean-2024-06-16
- **量子化**: int8
- **CER**: 約62% (要改善)

### 翻訳 (JA→KO, KO→JA)
- **モデル**: MarianMT (量子化ONNX)
- **chrF++**: 7.20 ❌ **使用不可**
- **問題**: 蒸留失敗、教師モデルから大幅劣化

---

## 改善案

### 短期（推奨アクション）
1. **Whisper base-q8 への移行検討** ← 最優先
   - 同サイズ（78MB vs 73MB）でCER 22% vs 54%
   - whisper.cpp / pywhispercpp で実装可能
2. **韓国語ASRも Whisper base-q8 推奨**
   - 現行sherpa-onnx Korean: CER 62%
   - Whisper base: CER 17.6% ← **検証済み（セバシ講演18分）**
   - 日本語と同様の大幅改善を確認

### 中期
1. whisper.cpp Android統合（NDK経由）
2. **翻訳モデル再構築** ← 最優先
   - LLM翻訳品質検証（Qwen3-32B / DeepSeek-R1）
   - 蒸留プロセスの見直し
   - AI Hub高品質データでの再学習
3. Whisper small-q8 (253MB) でさらなる精度向上

### 長期
1. 独自ASRモデルのトレーニング（ドメイン特化）
2. End-to-End Speech Translation
3. LLMベースのオンデバイス翻訳（Qwen-1.5B等）

---

## 量子化について

### 形式説明
- **Q8_0**: 8bit量子化 - 精度劣化最小（1-2%）、サイズ約55%
- **Q5_1**: 5bit量子化 - 精度劣化小（2-3%）、サイズ約40%
- **Q4_0**: 4bit量子化 - 精度劣化あり、サイズ約35%

### 推奨
日本語ASRには **Q8_0（int8相当）** を推奨。精度と速度のバランスが最適。

---

## 2026-02-10 更新: sherpa-onnx Whisper ONNX 実機テスト

### 実機ベンチマーク（Pixel 7a, CPU 4スレッド）

| モデル | サイズ | 速度 | 精度 |
|--------|--------|------|------|
| sherpa-onnx Transducer | 73MB | 高速 | CER 54% ❌ |
| whisper.cpp base-q8 | 78MB | 125秒 | CER 22% ❌遅い |
| **Whisper base ONNX int8** | 153MB | **500ms** | 🟠 誤認識あり |
| **Whisper small ONNX int8** | 359MB | **1.5-1.9秒** | ✅ 正確 |

### 結論
- **採用**: Whisper small ONNX int8 (359MB)
- **速度**: 1.5-1.9秒（実用的）
- **精度**: 誤認識ほぼなし

### 重要な発見
同じWhisperモデルでもランタイムで速度が劇的に違う:
- whisper.cpp: 125秒
- ONNX Runtime: 1.5秒
- → **60-80倍高速化**
