# ğŸ” RunPod ã‚¢ã‚¯ã‚»ã‚¹ã‚¬ã‚¤ãƒ‰

å†èµ·å‹•å¾Œã‚‚ä½œæ¥­ã‚’ç¶™ç¶šã§ãã‚‹ã‚ˆã†ã«ã€ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•ã¨ã‚ˆãä½¿ã†ã‚³ãƒãƒ³ãƒ‰ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚

---

## ğŸ“¡ SSHæ¥ç¶šæ–¹æ³•

### ç§˜å¯†éµã®é…ç½®
```bash
# ãƒ›ã‚¹ãƒˆãƒã‚·ãƒ³ã§ã®æ“ä½œ
ls ~/.ssh/id_ed25519
# ç§˜å¯†éµãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
# â€»ç§˜å¯†éµã®å†…å®¹ã¯ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã—ã¾ã›ã‚“
```

### SSHæ¥ç¶šã‚³ãƒãƒ³ãƒ‰
```bash
# RunPod ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¸ã®æ¥ç¶š
ssh root@157.157.221.29 -p 32309 -i ~/.ssh/id_ed25519

# æ¥ç¶šç¢ºèª
nvidia-smi
pwd
# æœŸå¾…: /root
```

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
```bash
cd /workspace/mt-ja-ko
```

---

## ğŸ”‘ WandBèªè¨¼

### APIãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—æ–¹æ³•
```bash
# ãƒ›ã‚¹ãƒˆãƒã‚·ãƒ³ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèª
cat ~/openclaw/wandb.txt
# ã¾ãŸã¯
cat ~/.openclaw/workspace/wandb.txt
```

### RunPodã§ã®ãƒ­ã‚°ã‚¤ãƒ³
```bash
# æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³
wandb login

# ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã§è¨­å®š
export WANDB_API_KEY=$(cat ~/openclaw/wandb.txt)
wandb login $WANDB_API_KEY
```

**é‡è¦:** APIãƒˆãƒ¼ã‚¯ãƒ³è‡ªä½“ã¯ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã—ã¾ã›ã‚“ã€‚

---

## ğŸš€ è¨“ç·´å†é–‹æ–¹æ³•

### ç¾åœ¨ã®è¨“ç·´çŠ¶æ³ç¢ºèª

```bash
# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep 'python3.*train.py' | grep -v grep

# æœ€æ–°ãƒ­ã‚°ç¢ºèª
tail -100 /workspace/mt-ja-ko/train_bs112.log

# GPUä½¿ç”¨çŠ¶æ³
nvidia-smi
```

### è¨“ç·´ãƒ­ã‚°ã‹ã‚‰WandB URLå–å¾—

```bash
grep 'View run at' /workspace/mt-ja-ko/train_bs112.log
# å‡ºåŠ›ä¾‹: https://wandb.ai/okamoto2okamoto-personal/huggingface/runs/09s29z5s
```

### è¨“ç·´å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼ˆè¨˜éŒ²ç”¨ï¼‰

#### ç¾åœ¨å®Ÿè¡Œä¸­ï¼ˆ2026-02-03ï¼‰
```bash
cd /workspace/mt-ja-ko

nohup python3 training/train.py \
    --data-dir data/matched \
    --tokenizer data/tokenized/spm.model \
    --output-dir /workspace/models/ja-ko-final \
    --epochs 10 \
    --batch-size 112 \
    --learning-rate 3e-4 \
    --num-workers 12 > train_bs112.log 2>&1 &

# WandB: https://wandb.ai/okamoto2okamoto-personal/huggingface/runs/09s29z5s
# è¨­å®š: Batch 112 x 2 = 224, å…¨24,420ã‚¹ãƒ†ãƒƒãƒ—, æ¨å®š6.8æ™‚é–“
```

#### éå»ã«æˆåŠŸã—ãŸè¨­å®šï¼ˆBLEU 33é”æˆæ™‚ï¼‰
```bash
python3 training/train.py \
    --data-dir data/clean \
    --tokenizer data/tokenized/spm.model \
    --output-dir /workspace/models/ja-ko \
    --epochs 10 \
    --batch-size 128 \
    --learning-rate 3e-4 \
    --num-workers 12

# çµæœ: Test BLEU 33.03
# WandB: https://wandb.ai/okamoto2okamoto-personal/huggingface/runs/zsh840l3
```

---

## ğŸ“Š ã‚ˆãä½¿ã†SSHã‚³ãƒãƒ³ãƒ‰é›†

### è¨“ç·´é€²æ—ç¢ºèª
```bash
# æœ€æ–°100è¡Œ
tail -100 /workspace/mt-ja-ko/train_bs112.log

# epochã¨BLEUã‚¹ã‚³ã‚¢ã®ã¿æŠ½å‡º
grep -E "'epoch':|eval_bleu" /workspace/mt-ja-ko/train_bs112.log | tail -20

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
tail -f /workspace/mt-ja-ko/train_bs112.log
```

### GPU/ãƒ¡ãƒ¢ãƒªç›£è¦–
```bash
# GPUä½¿ç”¨çŠ¶æ³
nvidia-smi

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ï¼ˆ1ç§’ã”ã¨æ›´æ–°ï¼‰
watch -n 1 nvidia-smi

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
free -h

# ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
df -h /workspace
```

### ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç†
```bash
# è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep train.py | grep -v grep

# ãƒ—ãƒ­ã‚»ã‚¹å¼·åˆ¶çµ‚äº†ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
pkill -9 -f 'python3.*train.py'

# GPUãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
nvidia-smi --query-compute-apps=pid --format=csv,noheader
```

### ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
ls -lh /workspace/mt-ja-ko/data/matched/
wc -l /workspace/mt-ja-ko/data/matched/*.ja

# ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¢ºèª
ls -lh /workspace/models/ja-ko-final/checkpoint-*/
du -sh /workspace/models/ja-ko-final/

# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®BLEUã‚¹ã‚³ã‚¢ç¢ºèª
find /workspace/models/ja-ko-final -name 'trainer_state.json' -exec tail {} \; | grep eval_bleu
```

### ãƒ­ã‚°åˆ†æ
```bash
# è¨“ç·´é€Ÿåº¦ï¼ˆit/sï¼‰ã®æ¨ç§»
grep 'it/s' /workspace/mt-ja-ko/train_bs112.log | tail -50

# ã‚¨ãƒ©ãƒ¼ç¢ºèª
grep -i error /workspace/mt-ja-ko/train_bs112.log
grep -i 'out of memory' /workspace/mt-ja-ko/train_bs112.log

# è©•ä¾¡çµæœä¸€è¦§
grep 'eval_bleu' /workspace/mt-ja-ko/train_bs112.log
```

---

## ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®å ´æ‰€

### ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
/workspace/mt-ja-ko/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ splits/          # å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆ1,035,749ãƒšã‚¢ï¼‰
â”‚   â”œâ”€â”€ cleaned/         # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼ˆ1,025,781ãƒšã‚¢ï¼‰
â”‚   â””â”€â”€ matched/         # è¨“ç·´ç”¨ï¼ˆtrain: 546,881, val/test: 14,392ï¼‰
â”‚       â”œâ”€â”€ train.ja
â”‚       â”œâ”€â”€ train.ko
â”‚       â”œâ”€â”€ val.ja
â”‚       â”œâ”€â”€ val.ko
â”‚       â”œâ”€â”€ test.ja
â”‚       â””â”€â”€ test.ko
â””â”€â”€ data/tokenized/
    â””â”€â”€ spm.model        # SentencePiece ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
```

### ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›
```
/workspace/models/
â”œâ”€â”€ ja-ko-final/         # ç¾åœ¨è¨“ç·´ä¸­
â”‚   â”œâ”€â”€ checkpoint-1000/
â”‚   â”œâ”€â”€ checkpoint-2000/
â”‚   â””â”€â”€ ...
â””â”€â”€ ja-ko-onnx-int8/     # ä»¥å‰ã®ONNXãƒ¢ãƒ‡ãƒ«
```

---

## ğŸ“ è¨“ç·´è¨­å®šãƒ¡ãƒ¢

### ç¾åœ¨ã®è¨“ç·´ï¼ˆ2026-02-03ï¼‰
- **æ–¹å‘:** æ—¥æœ¬èª â†’ éŸ“å›½èª
- **ãƒ‡ãƒ¼ã‚¿:** OPUS OpenSubtitlesï¼ˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ï¼‰
- **ãƒ¢ãƒ‡ãƒ«:** MarianMT (61M params)
- **è¨­å®š:**
  - Batch size: 112 per device Ã— 2 accumulation = 224 effective
  - Learning rate: 3e-4
  - Epochs: 10
  - Total steps: 24,420
- **æ¨å®šæ™‚é–“:** ç´„6.8æ™‚é–“
- **GPU:** RTX 4090
- **VRAMä½¿ç”¨:** 9.5GB / 24.5GB (39%)
- **GPUä½¿ç”¨ç‡:** 50%

### éå»ã®æˆåŠŸäº‹ä¾‹ï¼ˆBLEU 33é”æˆï¼‰
- **æ—¥æ™‚:** 2026-01-25
- **Batch size:** 128 Ã— 2 = 256
- **ãƒ‡ãƒ¼ã‚¿:** data/clean/ (OPUSéŸ“å›½èª)
- **çµæœ:** Test BLEU 33.03
- **è¨“ç·´æ™‚é–“:** ç´„50åˆ†ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ï¼‰

---

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### CUDA Out of Memory ã‚¨ãƒ©ãƒ¼
```bash
# ç¾åœ¨ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢
pkill -9 -f 'python3.*train.py'

# Batch sizeã‚’æ¸›ã‚‰ã—ã¦å†é–‹
# 112 â†’ 96 â†’ 80 â†’ 64 ã¨æ®µéšçš„ã«
nohup python3 training/train.py \
    --batch-size 96 \
    ... > train_bs96.log 2>&1 &
```

### è¨“ç·´ãŒæ­¢ã¾ã£ã¦ã„ã‚‹
```bash
# ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
ps aux | grep train.py

# GPUç¢ºèª
nvidia-smi

# ãƒ­ã‚°ã®æœ€å¾Œã‚’ç¢ºèª
tail -50 /workspace/mt-ja-ko/train_bs112.log

# å¿…è¦ãªã‚‰å¼·åˆ¶çµ‚äº†ã—ã¦å†é–‹
pkill -9 python3
# å†åº¦è¨“ç·´ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
```

### SSHæ¥ç¶šãŒåˆ‡ã‚ŒãŸ
```bash
# å†æ¥ç¶š
ssh root@157.157.221.29 -p 32309 -i ~/.ssh/id_ed25519

# è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ãŒç”Ÿãã¦ã„ã‚‹ã‹ç¢ºèª
ps aux | grep train.py

# ãƒ­ã‚°ã§é€²æ—ç¢ºèª
tail -100 /workspace/mt-ja-ko/train_bs112.log
```

### WandBã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç¢ºèª
```bash
# ãƒ­ã‚°ã‹ã‚‰WandB URLã‚’æŠ½å‡º
grep 'View run at' /workspace/mt-ja-ko/train_bs112.log

# ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã„ã¦é€²æ—ç¢ºèª
# loss, learning_rate, eval_bleu ãªã©ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
```

---

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- **WandB ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:** https://wandb.ai/okamoto2okamoto-personal/huggingface
- **å®Ÿé¨“ãƒ­ã‚°:** EXPERIMENTS.md
- **è¨“ç·´ã‚¬ã‚¤ãƒ‰:** TRAINING_GUIDE.md
- **RunPodãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:** RUNPOD_WORKFLOW.md

---

**æœ€çµ‚æ›´æ–°:** 2026-02-03  
**ä½œæˆè€…:** Sora (OpenClaw)
