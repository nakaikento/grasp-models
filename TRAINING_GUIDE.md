# ğŸš€ RunPodå­¦ç¿’ã‚¬ã‚¤ãƒ‰

MarianMTç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®RunPodå­¦ç¿’æ‰‹é †

## å‰ææ¡ä»¶

- RunPod GPU Podï¼ˆRTX 4090æ¨å¥¨ï¼‰
- ã“ã®ãƒªãƒã‚¸ãƒˆãƒªãŒã‚¯ãƒ­ãƒ¼ãƒ³æ¸ˆã¿
- ãƒ‡ãƒ¼ã‚¿ãŒæº–å‚™æ¸ˆã¿ï¼ˆ`data/splits/`, `data/tokenized/spm.model`ï¼‰

## ğŸ“‹ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. RunPodã«ãƒ­ã‚°ã‚¤ãƒ³

```bash
# SSHæ¥ç¶š
ssh root@<pod-ip> -p <port>

# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/nakaikento/mt-ja-ko.git
cd mt-ja-ko
```

### 2. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

### 3. å­¦ç¿’å®Ÿè¡Œ

#### **éŸ“å›½èª â†’ æ—¥æœ¬èª**ï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šï¼‰

```bash
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --use-teacher \
  --epochs 10 \
  --batch-size 64
```

#### **éŸ“å›½èª â†’ æ—¥æœ¬èª**ï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆï¼‰

```bash
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --generate-teacher \
  --epochs 10 \
  --batch-size 64
```

#### **æ—¥æœ¬èª â†’ éŸ“å›½èª**ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªï¼‰

```bash
python training/train_pair.py \
  --src-lang ja \
  --tgt-lang ko \
  --use-teacher \
  --epochs 10 \
  --batch-size 64
```

## ğŸ”§ ã‚ªãƒ—ã‚·ãƒ§ãƒ³

### åŸºæœ¬ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
|-----------|------|----------|
| `--src-lang` | ã‚½ãƒ¼ã‚¹è¨€èªï¼ˆja/koï¼‰ | **å¿…é ˆ** |
| `--tgt-lang` | ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªï¼ˆja/koï¼‰ | **å¿…é ˆ** |
| `--epochs` | ã‚¨ãƒãƒƒã‚¯æ•° | 10 |
| `--batch-size` | ãƒãƒƒãƒã‚µã‚¤ã‚º | 64 |
| `--learning-rate` | å­¦ç¿’ç‡ | 3e-4 |

### ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
|-----------|------|----------|
| `--use-teacher` | æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ | True |
| `--no-teacher` | OPUSç”Ÿãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ | False |
| `--generate-teacher` | æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆ | False |
| `--data-dir` | ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `data/splits` |
| `--teacher-dir` | æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `data/teacher` |
| `--tokenizer` | ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ‘ã‚¹ | `data/tokenized/spm.model` |

### ãã®ä»–

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
|-----------|------|----------|
| `--resume` | ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹ | ãªã— |
| `--num-workers` | DataLoaderãƒ¯ãƒ¼ã‚«ãƒ¼æ•° | 4 |

## ğŸ“Š é€²æ—ç¢ºèª

ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¸­ã€ä»¥ä¸‹ã®æƒ…å ±ãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã•ã‚Œã¾ã™ï¼š

```
Training: 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 8401/20000 [12:45<17:32, 11.03step/s, loss=1.2345, BLEU=28.50]
```

- **é€²æ—ãƒãƒ¼**: å…¨ã‚¹ãƒ†ãƒƒãƒ—ä¸­ã®ç¾åœ¨ä½ç½®
- **loss**: ç¾åœ¨ã®æå¤±å€¤ï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
- **BLEU**: è©•ä¾¡ã‚»ãƒƒãƒˆã®BLEUã‚¹ã‚³ã‚¢ï¼ˆé«˜ã„ã»ã©è‰¯ã„ã€ç›®æ¨™: >30ï¼‰

## ğŸ”„ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼†å†é–‹

### ä¸­æ–­ã—ãŸå­¦ç¿’ã‚’å†é–‹

```bash
# æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ç¢ºèª
ls -lt models/ko-ja/

# å†é–‹ï¼ˆä¾‹: checkpoint-8000ï¼‰
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --resume models/ko-ja/checkpoint-8000
```

### å®šæœŸä¿å­˜

- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§1000ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ä¿å­˜
- æœ€æ–°3ã¤ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ã¿ä¿æŒï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ç¯€ç´„ï¼‰
- Early Stopping: 3å›é€£ç¶šã§BLEUãŒæ”¹å–„ã—ãªã‘ã‚Œã°åœæ­¢

## ğŸ“ å‡ºåŠ›æ§‹æˆ

```
models/
  ko-ja/                          # éŸ“æ—¥ç¿»è¨³ãƒ¢ãƒ‡ãƒ«
    checkpoint-1000/              # ä¸­é–“ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
    checkpoint-2000/
    checkpoint-8000/              # æœ€æ–°
    config.json                   # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    pytorch_model.bin             # å­¦ç¿’æ¸ˆã¿é‡ã¿
    spm.model                     # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
    training_args.bin             # å­¦ç¿’è¨­å®š
  ja-ko/                          # æ—¥éŸ“ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¢å­˜ï¼‰
```

## ğŸ¯ ç›®æ¨™BLEU

| è¨€èªãƒšã‚¢ | ç›®æ¨™BLEU | é”æˆåŸºæº– |
|---------|---------|---------|
| ja â†’ ko | 30+ | Grasp v1.0.0ã§é”æˆæ¸ˆã¿ |
| ko â†’ ja | 30+ | ä»Šå›ã®ç›®æ¨™ |

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### RTX 4090ï¼ˆ24GB VRAMï¼‰

```bash
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --batch-size 64 \
  --num-workers 8
```

### RTX 3090 / A5000ï¼ˆ16GB VRAMï¼‰

```bash
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --batch-size 32 \
  --num-workers 4
```

### Google Colabï¼ˆT4 16GBï¼‰

```bash
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --batch-size 32 \
  --num-workers 2
```

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### CUDA Out of Memory

```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™
--batch-size 32

# ã¾ãŸã¯
--batch-size 16
```

### æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```bash
# è‡ªå‹•ç”Ÿæˆ
python training/train_pair.py \
  --src-lang ko \
  --tgt-lang ja \
  --generate-teacher
```

### ä¸­æ–­æ™‚ã®å¯¾å‡¦

1. Ctrl+Cã§å®‰å…¨ã«åœæ­¢ï¼ˆæœ€æ–°ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¾ã§ä¿å­˜æ¸ˆã¿ï¼‰
2. `--resume` ã§å†é–‹

## ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

å­¦ç¿’å®Œäº†å¾Œï¼š

1. **ONNXå¤‰æ›**
   ```bash
   python training/convert_to_onnx.py --model-dir models/ko-ja
   ```

2. **é‡å­åŒ–**
   ```bash
   python training/quantize_onnx.py --model-dir models/ko-ja
   ```

3. **GitHub Releaseã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
   ```bash
   # ko-ja-onnx.zip ã‚’ä½œæˆ
   cd models/ko-ja
   zip -r ../../ko-ja-onnx.zip encoder_model.onnx decoder_model_merged.onnx spm.model
   
   # Grasp ãƒªãƒã‚¸ãƒˆãƒªã§ãƒªãƒªãƒ¼ã‚¹ä½œæˆ
   gh release create v2.0.0 ko-ja-onnx.zip --title "v2.0.0 - åŒæ–¹å‘ç¿»è¨³" --notes "éŸ“æ—¥ç¿»è¨³ãƒ¢ãƒ‡ãƒ«è¿½åŠ "
   ```

## ğŸ’¡ Tips

- **wandbç„¡åŠ¹åŒ–æ¸ˆã¿**: ãƒ­ã‚°ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼ˆ`report_to=["none"]`ï¼‰
- **tqdmé€²æ—ãƒãƒ¼**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã§CLIå®Ÿè¡ŒãŒå¿«é©
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: Ctrl+Cã‚„ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å®‰å…¨ã«åœæ­¢
- **æ•™å¸«ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ç”Ÿæˆ**: `--generate-teacher` ã§1ã‚³ãƒãƒ³ãƒ‰å®Œçµ

---

**è³ªå•ãƒ»å•é¡ŒãŒã‚ã‚Œã°**: Kentoã«é€£çµ¡ ğŸ‘‹
