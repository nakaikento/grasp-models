#!/usr/bin/env python3
"""
ç¿»è¨³ã‚¨ãƒ©ãƒ¼åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

æœ€è‰¯æ¡ä»¶ vs æœ€æ‚ªæ¡ä»¶ã§50æ–‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡ã€‚
è‡ªå‹•æŒ‡æ¨™ã§ã¯æ¸¬ã‚Œãªã„ã€Œç›´è¨³çš„ã‹ã©ã†ã‹ã€ã‚’äººæ‰‹ã§åˆ¤æ–­ã™ã‚‹ãŸã‚ã®ææ–™ã‚’æä¾›ã€‚

ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:
- literal: æ–‡æ³•çš„ã«æ­£ã—ã„ãŒä¸è‡ªç„¶ï¼ˆç›´è¨³çš„ï¼‰
- mistranslation: æ„å‘³ãŒç•°ãªã‚‹ï¼ˆèª¤è¨³ï¼‰
- unnatural: è¡¨ç¾ãŒãŠã‹ã—ã„ï¼ˆä¸è‡ªç„¶ï¼‰
- omission: æƒ…å ±ãŒè½ã¡ã¦ã„ã‚‹ï¼ˆæƒ…å ±æ¬ è½ï¼‰
- good: å•é¡Œãªã—

ä½¿ç”¨æ–¹æ³•:
  python3 analyze_errors.py \
    --source data/flores/ja_source.txt \
    --reference data/flores/ko_reference.txt \
    --best translations/qwen3-32b-natural.txt \
    --worst translations/qwen3-32b-zero_shot.txt \
    --n-samples 50 \
    --output results/error_samples.json
"""

import argparse
import json
import random
from pathlib import Path
from dataclasses import dataclass, asdict

@dataclass
class ErrorSample:
    index: int
    source_ja: str
    reference_ko: str
    best_ko: str
    worst_ko: str
    # ä»¥ä¸‹ã¯äººæ‰‹ã§åŸ‹ã‚ã‚‹
    best_error_type: str = ""
    worst_error_type: str = ""
    notes: str = ""


def load_lines(path: Path) -> list[str]:
    with open(path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f]


def sample_diverse_errors(sources: list[str], references: list[str],
                          best: list[str], worst: list[str],
                          n_samples: int = 50, seed: int = 42) -> list[ErrorSample]:
    """å¤šæ§˜ãªã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
    random.seed(seed)
    
    n = min(len(sources), len(references), len(best), len(worst))
    
    # å·®åˆ†ãŒå¤§ãã„ã‚‚ã®ã‚’å„ªå…ˆçš„ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    # (best ã¨ worst ã®é•·ã•ã®å·®ã€ã¾ãŸã¯è¡¨é¢çš„ãªé¡ä¼¼åº¦ã§åˆ¤æ–­)
    candidates = []
    for i in range(n):
        diff_score = abs(len(best[i]) - len(worst[i])) / max(len(best[i]), len(worst[i]), 1)
        candidates.append((i, diff_score))
    
    # å·®åˆ†ãŒå¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½ã¨ä¸‹ä½ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    candidates.sort(key=lambda x: x[1], reverse=True)
    
    # ä¸Šä½25% + ãƒ©ãƒ³ãƒ€ãƒ 50% + ä¸‹ä½25%
    n_top = n_samples // 4
    n_random = n_samples // 2
    n_bottom = n_samples - n_top - n_random
    
    selected_indices = set()
    
    # å·®åˆ†ãŒå¤§ãã„ã‚‚ã®
    for idx, _ in candidates[:n_top]:
        selected_indices.add(idx)
    
    # å·®åˆ†ãŒå°ã•ã„ã‚‚ã®
    for idx, _ in candidates[-n_bottom:]:
        selected_indices.add(idx)
    
    # ãƒ©ãƒ³ãƒ€ãƒ 
    remaining = [i for i in range(n) if i not in selected_indices]
    random.shuffle(remaining)
    for idx in remaining[:n_random]:
        selected_indices.add(idx)
    
    # ErrorSampleä½œæˆ
    samples = []
    for idx in sorted(selected_indices)[:n_samples]:
        samples.append(ErrorSample(
            index=idx,
            source_ja=sources[idx],
            reference_ko=references[idx],
            best_ko=best[idx],
            worst_ko=worst[idx]
        ))
    
    return samples


def main():
    parser = argparse.ArgumentParser(description="ç¿»è¨³ã‚¨ãƒ©ãƒ¼åˆ†æ")
    parser.add_argument("--source", type=Path, required=True)
    parser.add_argument("--reference", type=Path, required=True)
    parser.add_argument("--best", type=Path, required=True, help="æœ€è‰¯æ¡ä»¶ã®ç¿»è¨³")
    parser.add_argument("--worst", type=Path, required=True, help="æœ€æ‚ªæ¡ä»¶ã®ç¿»è¨³")
    parser.add_argument("--n-samples", type=int, default=50)
    parser.add_argument("--output", type=Path, default=Path("results/error_samples.json"))
    parser.add_argument("--seed", type=int, default=42)
    args = parser.parse_args()
    
    # èª­ã¿è¾¼ã¿
    sources = load_lines(args.source)
    references = load_lines(args.reference)
    best = load_lines(args.best)
    worst = load_lines(args.worst)
    
    print(f"ğŸ“¥ Loaded {len(sources)} samples")
    print(f"ğŸ“Š Best condition: {args.best.stem}")
    print(f"ğŸ“Š Worst condition: {args.worst.stem}")
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    samples = sample_diverse_errors(
        sources, references, best, worst,
        n_samples=args.n_samples,
        seed=args.seed
    )
    
    print(f"\nğŸ“ Sampled {len(samples)} examples for error analysis")
    
    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    print("\n" + "="*80)
    print("PREVIEW (first 5 samples)")
    print("="*80)
    
    for sample in samples[:5]:
        print(f"\n[{sample.index}]")
        print(f"  JA:   {sample.source_ja[:60]}...")
        print(f"  REF:  {sample.reference_ko[:60]}...")
        print(f"  BEST: {sample.best_ko[:60]}...")
        print(f"  WRST: {sample.worst_ko[:60]}...")
    
    # ä¿å­˜
    args.output.parent.mkdir(parents=True, exist_ok=True)
    
    output_data = {
        'metadata': {
            'source_file': str(args.source),
            'reference_file': str(args.reference),
            'best_file': str(args.best),
            'worst_file': str(args.worst),
            'n_samples': len(samples),
            'seed': args.seed
        },
        'error_types': {
            'literal': 'æ–‡æ³•çš„ã«æ­£ã—ã„ãŒä¸è‡ªç„¶ï¼ˆç›´è¨³çš„ï¼‰',
            'mistranslation': 'æ„å‘³ãŒç•°ãªã‚‹ï¼ˆèª¤è¨³ï¼‰',
            'unnatural': 'è¡¨ç¾ãŒãŠã‹ã—ã„ï¼ˆä¸è‡ªç„¶ï¼‰',
            'omission': 'æƒ…å ±ãŒè½ã¡ã¦ã„ã‚‹ï¼ˆæƒ…å ±æ¬ è½ï¼‰',
            'good': 'å•é¡Œãªã—'
        },
        'samples': [asdict(s) for s in samples]
    }
    
    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Saved to {args.output}")
    print("\nğŸ“‹ Next steps:")
    print("   1. Open the JSON file")
    print("   2. For each sample, fill in:")
    print("      - best_error_type: literal/mistranslation/unnatural/omission/good")
    print("      - worst_error_type: literal/mistranslation/unnatural/omission/good")
    print("      - notes: (optional) any observations")
    print("   3. Run analyze_error_results.py to compute statistics")


if __name__ == "__main__":
    main()
