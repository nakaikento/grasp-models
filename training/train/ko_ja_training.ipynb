{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfU_2PFRLDiV"
   },
   "source": [
    "# ðŸ‡°ðŸ‡·â†’ðŸ‡¯ðŸ‡µ MarianMT å­¦ç¿’ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "éŸ“å›½èªžâ†’æ—¥æœ¬èªžç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "\n",
    "## æ‰‹é †\n",
    "1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "2. æ•™å¸«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ (NLLB-200)\n",
    "3. MarianMTå­¦ç¿’\n",
    "4. ONNXå¤‰æ›ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q9FEo9HLDiX"
   },
   "source": [
    "## 0. GPUç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lteyQv2PLDiX",
    "outputId": "c44d5d02-8c64-4c58-c20d-49d540dd5373"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie9-O_P1LDiX"
   },
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-x47BOfLDiY",
    "outputId": "d71f5c9c-2220-4b77-8ce3-9d1ab783b9bf"
   },
   "outputs": [],
   "source": [
    "# RunPodã®æ°¸ç¶šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
    "base_path = \"/workspace/grasp-models\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "%cd {base_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /workspace/huggingface_cache\n",
    "!ls /workspace/huggingface_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚­ãƒ£ãƒƒã‚·ãƒ¥å…ˆã‚’å®¹é‡ã®å¤§ãã„ /workspace é…ä¸‹ã«å¤‰æ›´\n",
    "os.environ['HF_HOME'] = '/workspace/huggingface_cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/workspace/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /root/.cache/huggingface/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFvK33wZLNPr",
    "outputId": "120046f7-5035-4c52-b46b-bed2e4479dac"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndIjAj7fLDiY",
    "outputId": "510266e5-6da2-4aaf-d46d-9f2f794e674f"
   },
   "outputs": [],
   "source": [
    "# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n",
    "# ã™ã§ã«ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ pull ã—ã¦æœ€æ–°ã«ã—ã¾ã™\n",
    "repo_url = \"https://github.com/nakaikento/grasp-models.git\"\n",
    "repo_dir = \"grasp-models\"\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    print(f\"Cloning repository from {repo_url}...\")\n",
    "    !git clone {repo_url}\n",
    "    %cd {repo_dir}\n",
    "else:\n",
    "    print(\"Repository already exists. Pulling latest changes...\")\n",
    "    %cd {repo_dir}\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ju_GF6XXLDiY",
    "outputId": "7c256d0e-27e9-484c-e355-85c21dae95d2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0srWKofLDiZ"
   },
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CvaTn-8LDiZ",
    "outputId": "25580f9c-7987-42d0-a4fa-a9ad80e9ae68"
   },
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª\n",
    "!ls -la data/splits/\n",
    "!wc -l data/splits/*.ja data/splits/*.ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNmn9h4HLDiZ",
    "outputId": "d65907f0-ae63-4afa-d279-062c6fffbf3b"
   },
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ç¢ºèª\n",
    "!ls -la data/tokenized/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR33kcnuLDia"
   },
   "source": [
    "## 3. æ•™å¸«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆKnowledge Distillationç”¨ï¼‰\n",
    "\n",
    "NLLB-200ã‚’ä½¿ã£ã¦é«˜å“è³ªãªæ—¥æœ¬èªžç¿»è¨³ã‚’ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0LQV4k8TPAV",
    "outputId": "c3a61e55-98c7-485c-89f6-a4a83497beac"
   },
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm data/teacher/train.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/teacher/train.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lk2QqcWRLDia",
    "outputId": "2d7c4935-ac37-4d46-f028-9b5fab33132c"
   },
   "outputs": [],
   "source": [
    "# éŸ“æ—¥ç¿»è¨³ç”¨æ•™å¸«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\n!python3 training/generate_teacher_data.py \\\n  --src_lang ko \\\n  --tgt_lang ja \\\n  --src_file data/splits/train.ko \\\n  --output_file data/teacher/train_ko_ja.ja \\\n  --batch_size 40 \\\n  --num_beams 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_sync():\n",
    "    ja_in = \"data/raw/OpenSubtitles.ko-ja.ja\"\n",
    "    ko_in = \"data/teacher/train.ja\"\n",
    "    \n",
    "    ja_out = \"data/clean/train.ko\"\n",
    "    ko_out = \"data/clean/train.ja\"\n",
    "    \n",
    "    os.makedirs(\"data/clean\", exist_ok=True)\n",
    "\n",
    "    with open(ja_in, 'r', encoding='utf-8') as f_ja, \\\n",
    "         open(ko_in, 'r', encoding='utf-8') as f_ko, \\\n",
    "         open(ja_out, 'w', encoding='utf-8') as o_ja, \\\n",
    "         open(ko_out, 'w', encoding='utf-8') as o_ko:\n",
    "        \n",
    "        for ja_line, ko_line in zip(f_ja, f_ko):\n",
    "            ja_line = ja_line.strip()\n",
    "            ko_line = ko_line.strip()\n",
    "            \n",
    "            # å¤±æ•—è¡Œã€ç©ºè¡Œã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "            if \"FAILED_TRANSLATION_CLEANED\" in ko_line or not ko_line:\n",
    "                continue\n",
    "            \n",
    "            o_ja.write(ja_line + \"\\n\")\n",
    "            o_ko.write(ko_line + \"\\n\")\n",
    "\n",
    "    print(f\"âœ¨ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼\")\n",
    "    print(f\"ðŸ“ ä¿å­˜å…ˆ: data/clean/train.ko, train.ja\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_and_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm data/teacher/train.ja\n",
    "# !wc -l data/teacher/train.ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l data/clean/train.ja\n",
    "!wc -l data/clean/train.ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def verify_parallel_data(ja_path, ko_path, num_samples=10):\n",
    "    with open(ja_path, 'r', encoding='utf-8') as f_ja:\n",
    "        ja_lines = [line.strip() for line in f_ja]\n",
    "    with open(ko_path, 'r', encoding='utf-8') as f_ko:\n",
    "        ko_lines = [line.strip() for line in f_ko]\n",
    "\n",
    "    total = len(ja_lines)\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ\")\n",
    "    print(f\"  ç·ãƒšã‚¢æ•°: {total:,} è¡Œ\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡º\n",
    "    indices = random.sample(range(total), num_samples)\n",
    "    \n",
    "    print(f\"\\nðŸ” ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ãƒã‚§ãƒƒã‚¯ ({num_samples}ä»¶)\")\n",
    "    print(\"-\" * 50)\n",
    "    for idx in sorted(indices):\n",
    "        ja = ja_lines[idx]\n",
    "        ko = ko_lines[idx]\n",
    "        \n",
    "        # ç°¡æ˜“çš„ãªå“è³ªæŒ‡æ¨™\n",
    "        # æ—¥æœ¬èªžã¨éŸ“å›½èªžã®é•·ã•ã®æ¯”çŽ‡ï¼ˆæ¥µç«¯ã«é•ã†å ´åˆã¯æ³¨æ„ï¼‰\n",
    "        ratio = len(ko) / len(ja) if len(ja) > 0 else 0\n",
    "        status = \"âœ…\" if 0.3 < ratio < 3.0 else \"âš ï¸\"\n",
    "\n",
    "        print(f\"[{idx+1}è¡Œç›®] {status}\")\n",
    "        print(f\"  æ—¥: {ja}\")\n",
    "        print(f\"  éŸ“: {ko}\")\n",
    "        print(f\"  (é•·ã•æ¯”: {ratio:.2f})\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "    # æœ€ã‚‚é•·ã„æ–‡ã®ãƒã‚§ãƒƒã‚¯ï¼ˆãƒã‚°ç™ºè¦‹ç”¨ï¼‰\n",
    "    print(\"\\nè¶…é•·æ–‡ãƒã‚§ãƒƒã‚¯ (ç•°å¸¸ãªç¹°ã‚Šè¿”ã—ãŒãªã„ã‹)\")\n",
    "    max_idx = max(range(total), key=lambda i: len(ja_lines[i]))\n",
    "    print(f\"[{max_idx+1}è¡Œç›®]\")\n",
    "    print(f\"  æ—¥: {ja_lines[max_idx][:100]}...\")\n",
    "    print(f\"  éŸ“: {ko_lines[max_idx][:100]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verify_parallel_data(\"data/clean/train.ko\", \"data/clean/train.ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWS8PUMcLDia"
   },
   "outputs": [],
   "source": [
    "# ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ã‚»ãƒ«ã§å®Ÿè¡Œ\n",
    "import shutil\n",
    "\n",
    "# NLLBãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆRunPodã®æ¨™æº–çš„ãªãƒ‘ã‚¹ï¼‰\n",
    "cache_dir = \"/workspace/huggingface_cache/models--facebook--nllb-200-3.3b\"\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(f\"âœ… {cache_dir} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ç©ºãå®¹é‡ãŒå¤§å¹…ã«å¢—ãˆãŸã¯ãšã§ã™ã€‚\")\n",
    "else:\n",
    "    print(\"âŒ æŒ‡å®šã®ãƒ‘ã‚¹ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -la /workspace/huggingface_cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBjhMiZ6LDia"
   },
   "source": [
    "## 4. MarianMTå­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /workspace/grasp-models/grasp-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "with open('data/clean/train.ko', 'r', encoding='utf-8') as f:\n",
    "    ja_data = f.readlines()\n",
    "with open('data/clean/train.ja', 'r', encoding='utf-8') as f:\n",
    "    ko_data = f.readlines()\n",
    "\n",
    "# è¡Œæ•°ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹æœ€çµ‚ç¢ºèª\n",
    "if len(ja_data) == len(ko_data):\n",
    "    print(f\"âœ… è¡Œæ•°ä¸€è‡´ç¢ºèª: {len(ja_data)} è¡Œ\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰² (å­¦ç¿’ç”¨ 98%, æ¤œè¨¼ç”¨ 1%, ãƒ†ã‚¹ãƒˆç”¨ 1%)\n",
    "    # 100ä¸‡è¡Œã‚ã‚‹ã®ã§ã€å„1%ï¼ˆç´„1ä¸‡è¡Œï¼‰ã‚ã‚Œã°è©•ä¾¡ã«ã¯ååˆ†ã§ã™\n",
    "    train_ja, temp_ja, train_ko, temp_ko = train_test_split(ja_data, ko_data, test_size=0.02, random_state=42)\n",
    "    val_ja, test_ja, val_ko, test_ko = train_test_split(temp_ja, temp_ko, test_size=0.5, random_state=42)\n",
    "\n",
    "    # ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "    os.makedirs('data/final', exist_ok=True)\n",
    "\n",
    "    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "    def save_list(path, data):\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.writelines(data)\n",
    "\n",
    "    save_list('data/final/train.ko', train_ja)\n",
    "    save_list('data/final/train.ja', train_ko)\n",
    "    save_list('data/final/val.ko', val_ja)\n",
    "    save_list('data/final/val.ja', val_ko)\n",
    "    save_list('data/final/test.ko', test_ja)\n",
    "    save_list('data/final/test.ja', test_ko)\n",
    "    \n",
    "    print(\"âœ… ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "else:\n",
    "    print(f\"âŒ è¡Œæ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“: JA={len(ja_data)}, KO={len(ko_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_alignment(ja_path, ko_path, num_samples=5):\n",
    "    with open(ja_path, 'r', encoding='utf-8') as f_ja, \\\n",
    "         open(ko_path, 'r', encoding='utf-8') as f_ko:\n",
    "        # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚readlinesã§ã¯ãªãã€æœ€å°è¡Œæ•°ã¾ã§èª­ã¿è¾¼ã¿\n",
    "        ja_lines = f_ja.readlines()\n",
    "        ko_lines = f_ko.readlines()\n",
    "\n",
    "    total_ja = len(ja_lines)\n",
    "    total_ko = len(ko_lines)\n",
    "    \n",
    "    print(f\"--- çµ±è¨ˆ ---\")\n",
    "    print(f\"æ—¥æœ¬èªžè¡Œæ•°: {total_ja}\")\n",
    "    print(f\"éŸ“å›½èªžè¡Œæ•°: {total_ko}\")\n",
    "    print(f\"å·®åˆ†: {abs(total_ja - total_ko)}\\n\")\n",
    "\n",
    "    def print_samples(indices, label):\n",
    "        print(f\"--- {label} ã®ã‚µãƒ³ãƒ—ãƒ« ---\")\n",
    "        for i in indices:\n",
    "            if i < len(ja_lines) and i < len(ko_lines):\n",
    "                print(f\"[{i+1}è¡Œç›®]\")\n",
    "                print(f\"æ—¥: {ja_lines[i].strip()}\")\n",
    "                print(f\"éŸ“: {ko_lines[i].strip()}\")\n",
    "                print(\"-\" * 30)\n",
    "\n",
    "    # 1. å…ˆé ­ (1ã€œ5è¡Œç›®)\n",
    "    print_samples(range(0, num_samples), \"å…ˆé ­\")\n",
    "    \n",
    "    # 2. ä¸­é–“ (50ä¸‡è¡Œç›®ã‚ãŸã‚Š)\n",
    "    middle_idx = 500000\n",
    "    print_samples(range(middle_idx, middle_idx + num_samples), \"ä¸­é–“\")\n",
    "    \n",
    "    # 3. æœ«å°¾ï¼ˆéŸ“å›½èªžãƒ‡ãƒ¼ã‚¿ã®æœ€å¾Œã®æ–¹ï¼‰\n",
    "    end_idx = total_ko - num_samples\n",
    "    print_samples(range(end_idx, end_idx + num_samples), \"æœ«å°¾ï¼ˆåŒæœŸå¯èƒ½ç¯„å›²ï¼‰\")\n",
    "\n",
    "# æ­£ã—ã„ãƒ‘ã‚¹ã§å®Ÿè¡Œ\n",
    "check_alignment('data/clean/train.ko', 'data/clean/train.ja')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "\n",
    "# èª­ã¿è¾¼ã¿\n",
    "with open('data/clean/train.ko', 'r') as f:\n",
    "    ja_lines = f.readlines()\n",
    "with open('data/clean/train.ja', 'r') as f:\n",
    "    ko_lines = f.readlines()\n",
    "\n",
    "total = len(ja_lines)\n",
    "train_end = total * 95 // 100\n",
    "val_end = total * 975 // 1000\n",
    "\n",
    "print(f\"Total: {total}\")\n",
    "print(f\"Train: 0 - {train_end} ({train_end} lines)\")\n",
    "print(f\"Val: {train_end} - {val_end} ({val_end - train_end} lines)\")\n",
    "print(f\"Test: {val_end} - {total} ({total - val_end} lines)\")\n",
    "\n",
    "# åˆ†å‰²ã—ã¦ä¿å­˜\n",
    "with open('data/clean/train.ko', 'w') as f:\n",
    "    f.writelines(ja_lines[:train_end])\n",
    "with open('data/clean/train.ja', 'w') as f:\n",
    "    f.writelines(ko_lines[:train_end])\n",
    "\n",
    "with open('data/clean/val.ko', 'w') as f:\n",
    "    f.writelines(ja_lines[train_end:val_end])\n",
    "with open('data/clean/val.ja', 'w') as f:\n",
    "    f.writelines(ko_lines[train_end:val_end])\n",
    "\n",
    "with open('data/clean/test.ko', 'w') as f:\n",
    "    f.writelines(ja_lines[val_end:])\n",
    "with open('data/clean/test.ja', 'w') as f:\n",
    "    f.writelines(ko_lines[val_end:])\n",
    "\n",
    "print(\"\\nåˆ†å‰²å®Œäº†!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ: {user_info['name']} ã¨ã—ã¦èªè¨¼ã•ã‚Œã¦ã„ã¾ã™\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¦ã„ãªã„ã‹ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQ-QRJdFLDiZ",
    "outputId": "a8834aaa-efeb-487f-ce0b-d829b4afdf26"
   },
   "outputs": [],
   "source": [
    "# wandbãƒ­ã‚°ã‚¤ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fwk0xMGFLDia"
   },
   "outputs": [],
   "source": [
    "# å­¦ç¿’å®Ÿè¡Œï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰\n",
    "!python training/train.py \\\n",
    "    --data-dir data/clean \\\n",
    "    --tokenizer data/tokenized/spm.model \\\n",
    "    --output-dir /workspace/models/ko-ja \\\n",
    "    --epochs 10 \\\n",
    "    --batch-size 128 \\\n",
    "    --learning-rate 3e-4 \\\n",
    "    --num-workers 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQQEwbHaLDia"
   },
   "outputs": [],
   "source": [
    "# ã¾ãŸã¯ï¼šOPUSãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ï¼ˆæ•™å¸«ãƒ‡ãƒ¼ã‚¿ãªã—ã€æ¯”è¼ƒç”¨ï¼‰\n",
    "# !python training/train.py \\\n",
    "#     --use-opus-target \\\n",
    "#     --output-dir /content/drive/MyDrive/grasp-models/models/ko-ja-opus \\\n",
    "#     --epochs 10 \\\n",
    "#     --batch-size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eV-vLpTLDib"
   },
   "source": [
    "## 5. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8szkY23LDib"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('/workspace/grasp-models/grasp-models')\n",
    "\n",
    "from transformers import MarianMTModel\n",
    "from training.train import SPMTokenizer\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "model_path = \"/workspace/models/ko-ja\"\n",
    "model = MarianMTModel.from_pretrained(model_path)\n",
    "tokenizer = SPMTokenizer(f\"{model_path}/spm.model\")\n",
    "\n",
    "# GPUä½¿ç”¨\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def translate(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=128, num_beams=4)\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆç¿»è¨³\n",
    "test_sentences = [\n",
    "    # ãƒ‰ãƒ©ãƒžå®šç•ª\n",
    "    \"ç§ã‚’ä¿¡ã˜ã¦ã€‚\",\n",
    "    \"å˜˜ã‚’ã¤ã‹ãªã„ã§ã€‚\",\n",
    "    \"ã‚‚ã†ä¸€åº¦ãƒãƒ£ãƒ³ã‚¹ã‚’ãã ã•ã„ã€‚\",\n",
    "    \"å›ã®ã“ã¨ãŒå¥½ãã ã€‚\",\n",
    "    \"è¡Œã‹ãªã„ã§ï¼\",\n",
    "    \n",
    "    # æ„Ÿæƒ…çš„ãªã‚·ãƒ¼ãƒ³\n",
    "    \"ã©ã†ã—ã¦ãã‚“ãªã“ã¨ã‚’è¨€ã†ã®ï¼Ÿ\",\n",
    "    \"å…¨éƒ¨ç§ã®ã›ã„ã ã€‚\",\n",
    "    \"å›ãŒã„ãªã„ã¨ç”Ÿãã¦ã„ã‘ãªã„ã€‚\",\n",
    "    \"è¨±ã—ã¦ãã‚Œã€‚\",\n",
    "    \"äºŒåº¦ã¨ä¼šã„ãŸããªã„ã€‚\",\n",
    "    \n",
    "    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç³»\n",
    "    \"é€ƒã’ã‚ï¼\",\n",
    "    \"å¾Œã‚ã«èª°ã‹ã„ã‚‹ï¼\",\n",
    "    \"æ™‚é–“ãŒãªã„ã€‚æ€¥ã’ï¼\",\n",
    "    \"ä¿ºã«ä»»ã›ã‚ã€‚\",\n",
    "    \"çµ¶å¯¾ã«è«¦ã‚ãªã„ã€‚\",\n",
    "    \n",
    "    # æ—¥å¸¸ãƒ‰ãƒ©ãƒž\n",
    "    \"ä»Šæ—¥ã¯æ®‹æ¥­ï¼Ÿ\",\n",
    "    \"å…ˆè¼©ã€é£²ã¿ã«è¡Œãã¾ã›ã‚“ã‹ï¼Ÿ\",\n",
    "    \"å½¼æ°ã¨åˆ¥ã‚ŒãŸã®ã€‚\",\n",
    "    \"çµå©šã—ã¦ãã ã•ã„ã€‚\",\n",
    "    \"ãŠæ¯ã•ã‚“ã€ã”ã‚ã‚“ãªã•ã„ã€‚\",\n",
    "]\n",
    "\n",
    "for ja in test_sentences:\n",
    "    ko = translate(ja)\n",
    "    print(f\"ðŸ‡¯ðŸ‡µ {ja}\")\n",
    "    print(f\"ðŸ‡°ðŸ‡· {ko}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo1f2tKoLDib"
   },
   "source": [
    "## 6. ONNXå¤‰æ›ï¼ˆAndroidç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q optimum[onnxruntime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXddhh1ZLDib"
   },
   "outputs": [],
   "source": [
    "# ONNXå¤‰æ›\n",
    "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "model_path = \"/workspace/models/ko-ja\"\n",
    "output_path = \"/workspace/models/ko-ja-onnx\"\n",
    "\n",
    "# å¤‰æ›\n",
    "print(\"ONNXå¤‰æ›ä¸­...\")\n",
    "ort_model = ORTModelForSeq2SeqLM.from_pretrained(\n",
    "    model_path,\n",
    "    export=True\n",
    ")\n",
    "\n",
    "# ä¿å­˜\n",
    "ort_model.save_pretrained(output_path)\n",
    "\n",
    "# ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚‚ã‚³ãƒ”ãƒ¼\n",
    "shutil.copy(f\"{model_path}/spm.model\", f\"{output_path}/spm.model\")\n",
    "\n",
    "print(f\"âœ… å®Œäº†: {output_path}\")\n",
    "\n",
    "# ã‚µã‚¤ã‚ºç¢ºèª\n",
    "!ls -lh {output_path}/\n",
    "!du -sh {output_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qURAheqsLDib"
   },
   "outputs": [],
   "source": [
    "# å¤‰æ›å¾Œã®ãƒ†ã‚¹ãƒˆ\n",
    "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
    "import sys\n",
    "sys.path.append('/workspace/grasp-models/grasp-models')\n",
    "from training.train import SPMTokenizer\n",
    "\n",
    "# ONNXãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "ort_model = ORTModelForSeq2SeqLM.from_pretrained(output_path)\n",
    "tokenizer = SPMTokenizer(f\"{output_path}/spm.model\")\n",
    "\n",
    "def translate_onnx(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = ort_model.generate(**inputs, max_length=128, num_beams=4)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆ\n",
    "test = [\n",
    "    \"ã“ã‚“ã«ã¡ã¯\",\n",
    "    \"é€ƒã’ã‚ï¼\",\n",
    "    \"å›ã®ã“ã¨ãŒå¥½ãã ã€‚\",\n",
    "]\n",
    "\n",
    "for ja in test:\n",
    "    ko = translate_onnx(ja)\n",
    "    print(f\"ðŸ‡¯ðŸ‡µ {ja} â†’ ðŸ‡°ðŸ‡· {ko}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡å­åŒ–ã—ã¦è»½é‡åŒ–\n",
    "from optimum.onnxruntime import ORTQuantizer\n",
    "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = \"/workspace/models/ko-ja-onnx\"\n",
    "quantized_path = \"/workspace/models/ko-ja-onnx-int8\"\n",
    "\n",
    "Path(quantized_path).mkdir(exist_ok=True)\n",
    "\n",
    "# é‡å­åŒ–è¨­å®š\n",
    "qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False)\n",
    "\n",
    "# å…¨ONNXãƒ•ã‚¡ã‚¤ãƒ«ã‚’é‡å­åŒ–\n",
    "onnx_files = [\n",
    "    \"encoder_model.onnx\",\n",
    "    \"decoder_model.onnx\", \n",
    "    \"decoder_with_past_model.onnx\"\n",
    "]\n",
    "\n",
    "for onnx_file in onnx_files:\n",
    "    print(f\"é‡å­åŒ–ä¸­: {onnx_file}\")\n",
    "    quantizer = ORTQuantizer.from_pretrained(output_path, file_name=onnx_file)\n",
    "    quantizer.quantize(save_dir=quantized_path, quantization_config=qconfig)\n",
    "\n",
    "# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼\n",
    "shutil.copy(f\"{output_path}/config.json\", quantized_path)\n",
    "shutil.copy(f\"{output_path}/generation_config.json\", quantized_path)\n",
    "shutil.copy(f\"{output_path}/spm.model\", quantized_path)\n",
    "\n",
    "print(\"\\nâœ… é‡å­åŒ–å®Œäº†!\")\n",
    "\n",
    "# ã‚µã‚¤ã‚ºç¢ºèª\n",
    "!ls -lh {quantized_path}/\n",
    "!du -sh {quantized_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForSeq2SeqLM\n",
    "import sys\n",
    "sys.path.append('/workspace/grasp-models/grasp-models')\n",
    "from training.train import SPMTokenizer\n",
    "\n",
    "# é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "quantized_path = \"/workspace/models/ko-ja-onnx-int8\"\n",
    "ort_model = ORTModelForSeq2SeqLM.from_pretrained(quantized_path)\n",
    "tokenizer = SPMTokenizer(f\"{quantized_path}/spm.model\")\n",
    "\n",
    "def translate_q(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = ort_model.generate(**inputs, max_length=128, num_beams=4)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# é‡å­åŒ–å‰å¾Œã§å“è³ªæ¯”è¼ƒ\n",
    "test = [\n",
    "    # ãƒ‰ãƒ©ãƒžå®šç•ª\n",
    "    \"ç§ã‚’ä¿¡ã˜ã¦ã€‚\",\n",
    "    \"å˜˜ã‚’ã¤ã‹ãªã„ã§ã€‚\",\n",
    "    \"ã‚‚ã†ä¸€åº¦ãƒãƒ£ãƒ³ã‚¹ã‚’ãã ã•ã„ã€‚\",\n",
    "    \"å›ã®ã“ã¨ãŒå¥½ãã ã€‚\",\n",
    "    \"è¡Œã‹ãªã„ã§ï¼\",\n",
    "    \n",
    "    # æ„Ÿæƒ…çš„ãªã‚·ãƒ¼ãƒ³\n",
    "    \"ã©ã†ã—ã¦ãã‚“ãªã“ã¨ã‚’è¨€ã†ã®ï¼Ÿ\",\n",
    "    \"å…¨éƒ¨ç§ã®ã›ã„ã ã€‚\",\n",
    "    \"å›ãŒã„ãªã„ã¨ç”Ÿãã¦ã„ã‘ãªã„ã€‚\",\n",
    "    \"è¨±ã—ã¦ãã‚Œã€‚\",\n",
    "    \"äºŒåº¦ã¨ä¼šã„ãŸããªã„ã€‚\",\n",
    "    \n",
    "    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç³»\n",
    "    \"é€ƒã’ã‚ï¼\",\n",
    "    \"å¾Œã‚ã«èª°ã‹ã„ã‚‹ï¼\",\n",
    "    \"æ™‚é–“ãŒãªã„ã€‚æ€¥ã’ï¼\",\n",
    "    \"ä¿ºã«ä»»ã›ã‚ã€‚\",\n",
    "    \"çµ¶å¯¾ã«è«¦ã‚ãªã„ã€‚\",\n",
    "    \n",
    "    # æ—¥å¸¸ãƒ‰ãƒ©ãƒž\n",
    "    \"ä»Šæ—¥ã¯æ®‹æ¥­ï¼Ÿ\",\n",
    "    \"å…ˆè¼©ã€é£²ã¿ã«è¡Œãã¾ã›ã‚“ã‹ï¼Ÿ\",\n",
    "    \"å½¼æ°ã¨åˆ¥ã‚ŒãŸã®ã€‚\",\n",
    "    \"çµå©šã—ã¦ãã ã•ã„ã€‚\",\n",
    "    \"ãŠæ¯ã•ã‚“ã€ã”ã‚ã‚“ãªã•ã„ã€‚\",\n",
    "]\n",
    "\n",
    "print(\"ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆã€‘\\n\")\n",
    "for ja in test:\n",
    "    ko = translate_q(ja)\n",
    "    print(f\"ðŸ‡¯ðŸ‡µ {ja}\")\n",
    "    print(f\"ðŸ‡°ðŸ‡· {ko}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDfc9UgwLDib"
   },
   "source": [
    "## 7. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ `workspace/models/` ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«:\n",
    "- encoder_model_quantized.onnx (35MB)\n",
    "- decoder_model_quantized.onnx (57MB)\n",
    "- spm.model (807KB)\n",
    "\n",
    "é«˜é€ŸæŽ¨è«–ç”¨ï¼ˆæŽ¨å¥¨ï¼‰:\n",
    "\n",
    "- decoder_with_past_model_quantized.onnx (54MB)\n",
    "\n",
    "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«:\n",
    "\n",
    "- config.json\n",
    "- generation_config.json"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}